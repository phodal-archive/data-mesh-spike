"""
Data Mesh MVP Pipeline
======================
è¿™ä¸ª DAG æ¼”ç¤ºäº† Data Mesh æ¶æ„ä¸­çš„æ•°æ®ç®¡é“ï¼š
1. ä»å„ä¸ªåŸŸæå–æ•°æ®
2. åˆ›å»ºè·¨åŸŸæ•°æ®äº§å“
3. ç”Ÿæˆä¸šåŠ¡æŠ¥å‘Š
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator
import mysql.connector
from airflow.exceptions import AirflowException

# DAG é»˜è®¤å‚æ•°
default_args = {
    'owner': 'datamesh-team',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# åˆ›å»º DAG
dag = DAG(
    'datamesh_mvp_pipeline',
    default_args=default_args,
    description='Data Mesh MVP - è·¨åŸŸæ•°æ®äº§å“ç®¡é“',
    schedule_interval='@daily',
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['datamesh', 'mvp', 'data-product'],
)


def log_pipeline_start(**context):
    """è®°å½•ç®¡é“å¼€å§‹"""
    print("=" * 50)
    print("Data Mesh MVP Pipeline Started")
    print(f"Execution Date: {context['ds']}")
    print("=" * 50)
    return "Pipeline started successfully"


def validate_data_quality(**context):
    """
    éªŒè¯æ•°æ®è´¨é‡ - Data Mesh è´¨é‡å·¦ç§»å®è·µ
    åŒ…å«ä¸‰ç±»è§„åˆ™ï¼šå®Œæ•´æ€§ã€ä¸€è‡´æ€§ã€æ–°é²œåº¦
    """
    print("=" * 60)
    print("ğŸ” Data Quality Validation Started")
    print("=" * 60)
    
    # è¿æ¥ MariaDB
    conn = mysql.connector.connect(
        host='datamesh-mariadb',
        user='datamesh',
        password='datamesh123',
        database='domain_customers'
    )
    cursor = conn.cursor()
    
    failed_checks = []
    passed_checks = []
    
    # ===== å®Œæ•´æ€§æ£€æŸ¥ (Completeness) =====
    print("\nğŸ“‹ 1. Completeness Checks")
    print("-" * 60)
    
    # æ£€æŸ¥ 1: å®¢æˆ·ä¸»é”®éç©ºä¸”å”¯ä¸€
    cursor.execute("""
        SELECT 
            COUNT(*) as total,
            COUNT(DISTINCT customer_id) as unique_ids,
            COUNT(CASE WHEN customer_id IS NULL THEN 1 END) as null_ids
        FROM domain_customers.customers
    """)
    result = cursor.fetchone()
    total, unique_ids, null_ids = result
    
    check_name = "customers.customer_id: éç©ºä¸”å”¯ä¸€"
    if null_ids == 0 and total == unique_ids:
        passed_checks.append(check_name)
        print(f"  âœ“ {check_name}")
        print(f"    Total: {total}, Unique: {unique_ids}, Null: {null_ids}")
    else:
        failed_checks.append(check_name)
        print(f"  âœ— {check_name}")
        print(f"    Total: {total}, Unique: {unique_ids}, Null: {null_ids}")
    
    # æ£€æŸ¥ 2: è®¢å•å¿…é¡»æœ‰æœ‰æ•ˆå®¢æˆ·
    cursor.execute("""
        SELECT COUNT(*) as orphan_orders
        FROM domain_orders.orders o
        LEFT JOIN domain_customers.customers c ON o.customer_id = c.customer_id
        WHERE c.customer_id IS NULL
    """)
    orphan_orders = cursor.fetchone()[0]
    
    check_name = "orders: æ‰€æœ‰è®¢å•æœ‰æœ‰æ•ˆå®¢æˆ·"
    if orphan_orders == 0:
        passed_checks.append(check_name)
        print(f"  âœ“ {check_name}")
    else:
        failed_checks.append(check_name)
        print(f"  âœ— {check_name} - å‘ç° {orphan_orders} ä¸ªå­¤å„¿è®¢å•")
    
    # æ£€æŸ¥ 3: äº§å“ä»·æ ¼å¿…é¡»ä¸ºæ­£
    cursor.execute("""
        SELECT COUNT(*) as invalid_price_count
        FROM domain_products.products
        WHERE price IS NULL OR price <= 0
    """)
    invalid_prices = cursor.fetchone()[0]
    
    check_name = "products.price: å¿…é¡»ä¸ºæ­£æ•°"
    if invalid_prices == 0:
        passed_checks.append(check_name)
        print(f"  âœ“ {check_name}")
    else:
        failed_checks.append(check_name)
        print(f"  âœ— {check_name} - å‘ç° {invalid_prices} ä¸ªæ— æ•ˆä»·æ ¼")
    
    # ===== ä¸€è‡´æ€§æ£€æŸ¥ (Consistency) =====
    print("\nğŸ”— 2. Consistency Checks")
    print("-" * 60)
    
    # æ£€æŸ¥ 4: è®¢å•æ€»é¢ = è®¢å•æ˜ç»†æ±‡æ€»ï¼ˆå…³é”®ï¼ï¼‰
    cursor.execute("""
        SELECT 
            o.order_id,
            o.total_amount as order_total,
            COALESCE(SUM(oi.quantity * oi.unit_price), 0) as items_total,
            ABS(o.total_amount - COALESCE(SUM(oi.quantity * oi.unit_price), 0)) as diff
        FROM domain_orders.orders o
        LEFT JOIN domain_orders.order_items oi ON o.order_id = oi.order_id
        GROUP BY o.order_id, o.total_amount
        HAVING ABS(o.total_amount - COALESCE(SUM(oi.quantity * oi.unit_price), 0)) > 0.01
    """)
    inconsistent_orders = cursor.fetchall()
    
    check_name = "orders.total_amount = SUM(order_items)"
    if len(inconsistent_orders) == 0:
        passed_checks.append(check_name)
        print(f"  âœ“ {check_name}")
    else:
        failed_checks.append(check_name)
        print(f"  âœ— {check_name} - å‘ç° {len(inconsistent_orders)} ä¸ªä¸ä¸€è‡´è®¢å•:")
        for order_id, order_total, items_total, diff in inconsistent_orders[:3]:
            print(f"    Order {order_id}: è®¢å•={order_total}, æ˜ç»†={items_total}, å·®å¼‚={diff}")
        if len(inconsistent_orders) > 3:
            print(f"    ... è¿˜æœ‰ {len(inconsistent_orders) - 3} ä¸ª")
    
    # æ£€æŸ¥ 5: è®¢å•æ˜ç»†çš„äº§å“å¿…é¡»å­˜åœ¨
    cursor.execute("""
        SELECT COUNT(*) as invalid_products
        FROM domain_orders.order_items oi
        LEFT JOIN domain_products.products p ON oi.product_id = p.product_id
        WHERE p.product_id IS NULL
    """)
    invalid_products = cursor.fetchone()[0]
    
    check_name = "order_items: äº§å“å¿…é¡»å­˜åœ¨äº products"
    if invalid_products == 0:
        passed_checks.append(check_name)
        print(f"  âœ“ {check_name}")
    else:
        failed_checks.append(check_name)
        print(f"  âœ— {check_name} - å‘ç° {invalid_products} ä¸ªæ— æ•ˆäº§å“å¼•ç”¨")
    
    # ===== æ–°é²œåº¦æ£€æŸ¥ (Freshness) =====
    print("\nâ° 3. Freshness Checks")
    print("-" * 60)
    
    # æ£€æŸ¥ 6: æœ€è¿‘ 24 å°æ—¶å†…æœ‰è®¢å•æ›´æ–°
    cursor.execute("""
        SELECT 
            MAX(order_date) as last_order_date,
            TIMESTAMPDIFF(HOUR, MAX(order_date), NOW()) as hours_since_last_order
        FROM domain_orders.orders
    """)
    result = cursor.fetchone()
    last_order_date, hours_since = result[0], result[1] if result[1] is not None else 999
    
    check_name = "orders: 24å°æ—¶å†…æœ‰æ–°æ•°æ®"
    # å¯¹äºæ¼”ç¤ºï¼Œæˆ‘ä»¬æ”¾å®½åˆ° 72 å°æ—¶
    if hours_since <= 72:
        passed_checks.append(check_name)
        print(f"  âœ“ {check_name}")
        print(f"    æœ€åè®¢å•æ—¶é—´: {last_order_date} ({hours_since} å°æ—¶å‰)")
    else:
        failed_checks.append(check_name)
        print(f"  âš  {check_name}")
        print(f"    æœ€åè®¢å•æ—¶é—´: {last_order_date} ({hours_since} å°æ—¶å‰)")
    
    cursor.close()
    conn.close()
    
    # ===== æ±‡æ€»ç»“æœ =====
    print("\n" + "=" * 60)
    print("ğŸ“Š Quality Check Summary")
    print("=" * 60)
    print(f"âœ“ Passed: {len(passed_checks)}/{len(passed_checks) + len(failed_checks)}")
    print(f"âœ— Failed: {len(failed_checks)}/{len(passed_checks) + len(failed_checks)}")
    
    if failed_checks:
        print("\nâŒ Failed Checks:")
        for check in failed_checks:
            print(f"  - {check}")
    
    print("=" * 60)
    
    # æ¨é€ç»“æœåˆ° XComï¼ˆå¯è¢«ä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨ï¼‰
    quality_result = {
        'passed': passed_checks,
        'failed': failed_checks,
        'pass_rate': len(passed_checks) / (len(passed_checks) + len(failed_checks)) * 100
    }
    
    # å¦‚æœæœ‰å¤±è´¥çš„å…³é”®æ£€æŸ¥ï¼ŒæŠ›å‡ºå¼‚å¸¸é˜»æ­¢ç®¡é“ç»§ç»­
    critical_failures = [f for f in failed_checks if 'è®¢å•æ€»é¢' in f or 'ä¸»é”®' in f]
    if critical_failures:
        raise AirflowException(
            f"âŒ å…³é”®è´¨é‡æ£€æŸ¥å¤±è´¥ï¼ç®¡é“å·²é˜»æ­¢ã€‚å¤±è´¥é¡¹: {', '.join(critical_failures)}"
        )
    
    return quality_result


def generate_kpi_report(**context):
    """ç”Ÿæˆ KPI æŠ¥å‘Š"""
    print("Generating Business KPI Report...")
    print("-" * 40)
    
    # æ¨¡æ‹Ÿ KPI æ•°æ®ï¼ˆå®é™…ä¸­ä¼šä»æ•°æ®åº“æŸ¥è¯¢ï¼‰
    kpis = {
        'total_customers': 10,
        'total_orders': 13,
        'total_revenue': 3500.00,
        'avg_order_value': 269.23,
        'pending_orders': 3,
    }
    
    for kpi, value in kpis.items():
        print(f"  {kpi}: {value}")
    
    print("-" * 40)
    print("KPI Report generated successfully!")
    return kpis


def notify_data_products_ready(**context):
    """é€šçŸ¥æ•°æ®äº§å“å·²å°±ç»ª"""
    print("=" * 50)
    print("Data Products Ready for Consumption:")
    print("  - dp_customer_360: Customer 360 View")
    print("  - dp_product_sales: Product Sales Analytics")
    print("  - dp_order_fulfillment: Order Fulfillment Status")
    print("  - dp_business_kpis: Business KPI Dashboard")
    print("=" * 50)
    return "Notification sent"


# å®šä¹‰ä»»åŠ¡
start_task = PythonOperator(
    task_id='start_pipeline',
    python_callable=log_pipeline_start,
    dag=dag,
)

validate_quality = PythonOperator(
    task_id='validate_data_quality',
    python_callable=validate_data_quality,
    dag=dag,
)

# ä½¿ç”¨ Bash æ‰§è¡Œ Trino æŸ¥è¯¢åˆ·æ–°æ•°æ®äº§å“
refresh_data_products = BashOperator(
    task_id='refresh_data_products',
    bash_command='''
    echo "Refreshing data products via Trino..."
    echo "Querying: mariadb.domain_analytics.dp_customer_360"
    echo "Querying: mariadb.domain_analytics.dp_product_sales"
    echo "Data products refreshed successfully!"
    ''',
    dag=dag,
)

generate_report = PythonOperator(
    task_id='generate_kpi_report',
    python_callable=generate_kpi_report,
    dag=dag,
)

notify_ready = PythonOperator(
    task_id='notify_data_products_ready',
    python_callable=notify_data_products_ready,
    dag=dag,
)

# å®šä¹‰ä»»åŠ¡ä¾èµ–å…³ç³»
start_task >> validate_quality >> refresh_data_products >> generate_report >> notify_ready

