#!/bin/bash
# ============================================
# Data Mesh MVP å®Œæ•´éªŒè¯è„šæœ¬
# éªŒè¯æ‰€æœ‰ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œã€æ•°æ®é“¾è·¯æ˜¯å¦é—­ç¯
# ============================================

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘           Data Mesh MVP å®Œæ•´éªŒè¯                           â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# é¢œè‰²å®šä¹‰
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

PASSED=0
FAILED=0
WARNINGS=0

check_pass() {
    echo -e "  ${GREEN}âœ“${NC} $1"
    PASSED=$((PASSED + 1))
}

check_fail() {
    echo -e "  ${RED}âœ—${NC} $1"
    FAILED=$((FAILED + 1))
}

check_warn() {
    echo -e "  ${YELLOW}âš ${NC} $1"
    WARNINGS=$((WARNINGS + 1))
}

section() {
    echo ""
    echo -e "${CYAN}â”â”â” $1 â”â”â”${NC}"
}

# ============================================
# 1. æ£€æŸ¥å®¹å™¨çŠ¶æ€
# ============================================
section "1. å®¹å™¨çŠ¶æ€æ£€æŸ¥"

# Stack 1 æœåŠ¡
stack1_services=("datamesh-mariadb" "datamesh-trino" "datamesh-airflow-webserver" "datamesh-airflow-scheduler" "datamesh-openmetadata" "datamesh-elasticsearch")
# Stack 2 æœåŠ¡
stack2_services=("datamesh-prometheus" "datamesh-grafana" "datamesh-jaeger" "datamesh-otel-collector" "datamesh-blackbox-exporter" "datamesh-pushgateway" "datamesh-superset" "datamesh-neo4j" "datamesh-backstage")

echo "  Stack 1 (æ•°æ®å¹³å°æ ¸å¿ƒ):"
for service in "${stack1_services[@]}"; do
    if docker ps --format '{{.Names}}' 2>/dev/null | grep -q "^${service}$"; then
        check_pass "$service"
    else
        check_fail "$service æœªè¿è¡Œ"
    fi
done

echo ""
echo "  Stack 2 (å¯è§‚æµ‹æ€§ & é—¨æˆ·):"
for service in "${stack2_services[@]}"; do
    if docker ps --format '{{.Names}}' 2>/dev/null | grep -q "^${service}$"; then
        check_pass "$service"
    else
        # pushgateway/blackbox/backstage å¯èƒ½æ˜¯å¯é€‰çš„
        if [[ "$service" == "datamesh-backstage" || "$service" == "datamesh-pushgateway" || "$service" == "datamesh-blackbox-exporter" ]]; then
            check_warn "$service æœªè¿è¡Œ (å¯é€‰)"
        else
            check_fail "$service æœªè¿è¡Œ"
        fi
    fi
done

# ============================================
# 2. HTTP å¥åº·æ£€æŸ¥
# ============================================
section "2. HTTP å¥åº·æ£€æŸ¥"

check_http() {
    local name=$1
    local url=$2
    local code=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout 5 "$url" 2>/dev/null || echo "000")
    if [[ "$code" =~ ^(200|204|301|302)$ ]]; then
        check_pass "$name ($url)"
    else
        check_fail "$name ($url) - HTTP $code"
    fi
}

check_http "Trino" "http://localhost:8080/v1/info"
check_http "Airflow" "http://localhost:8081/health"
check_http "OpenMetadata" "http://localhost:8585/api/v1/system/version"
check_http "Prometheus" "http://localhost:9090/-/healthy"
check_http "Grafana" "http://localhost:3000/api/health"
check_http "Jaeger" "http://localhost:16686"
check_http "Superset" "http://localhost:8089/health"
check_http "Neo4j" "http://localhost:7474"

# ============================================
# 3. æ•°æ®åŸŸè¿é€šæ€§ (Trino â†’ MariaDB)
# ============================================
section "3. æ•°æ®åŸŸè¿é€šæ€§ (Trino è·¨åŸŸæŸ¥è¯¢)"

trino_scalar() {
    # ç”¨ TSV è¾“å‡ºæ ¼å¼æ‹¿åˆ°ç¨³å®šçš„æ ‡é‡ç»“æœï¼ˆé¿å… warning/è¡¨æ ¼æ ¼å¼å¹²æ‰°ï¼‰
    docker exec datamesh-trino trino --output-format TSV --execute "$1" 2>/dev/null \
      | tr -d '\r' \
      | grep -E '^[0-9]+(\\.[0-9]+)?$' \
      | tail -1
}

trino_row() {
    # è¿”å›æœ€åä¸€è¡Œæ•°æ®ï¼ˆç”¨äº KPI ç­‰éçº¯æ•°å­—è¾“å‡ºï¼‰
    docker exec datamesh-trino trino --output-format TSV --execute "$1" 2>/dev/null \
      | tr -d '\r' \
      | tail -1
}

domains=("domain_customers.customers" "domain_orders.orders" "domain_products.products")
for table in "${domains[@]}"; do
    result=$(trino_scalar "SELECT COUNT(*) FROM mariadb.$table")
    if [[ "$result" =~ ^[0-9]+$ ]] && [ "$result" -gt 0 ]; then
        check_pass "mariadb.$table: $result æ¡"
    else
        check_fail "mariadb.$table æŸ¥è¯¢å¤±è´¥"
    fi
done

# ============================================
# 4. æ•°æ®äº§å“è§†å›¾
# ============================================
section "4. æ•°æ®äº§å“è§†å›¾ (dp_*)"

data_products=("dp_customer_360" "dp_product_sales" "dp_order_fulfillment" "dp_business_kpis")
dp_all_ok=true

for dp in "${data_products[@]}"; do
    result=$(trino_scalar "SELECT COUNT(*) FROM mariadb.domain_analytics.$dp" 2>/dev/null)
    if [[ "$result" =~ ^[0-9]+$ ]] && [ "$result" -ge 0 ]; then
        check_pass "$dp: $result æ¡"
    else
        check_fail "$dp ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥"
        dp_all_ok=false
    fi
done

if [ "$dp_all_ok" = false ]; then
    echo ""
    echo -e "  ${YELLOW}ğŸ’¡ æç¤º: è¿è¡Œ ./scripts/init-data-products.sh åˆå§‹åŒ–æ•°æ®äº§å“è§†å›¾${NC}"
fi

# ============================================
# 5. Airflow DAG çŠ¶æ€
# ============================================
section "5. Airflow DAG çŠ¶æ€"

dag_check() {
    local dag_id=$1
    # æ£€æŸ¥ DAG æ˜¯å¦å­˜åœ¨ä¸”æœªæš‚åœ
    local info=$(docker exec datamesh-airflow-scheduler airflow dags list 2>/dev/null | grep "^$dag_id" || echo "")
    if [ -n "$info" ]; then
        local paused=$(echo "$info" | awk '{print $NF}')
        if [ "$paused" == "False" ]; then
            check_pass "$dag_id (å·²å¯ç”¨)"
        else
            check_warn "$dag_id (å·²æš‚åœ)"
        fi
    else
        check_fail "$dag_id ä¸å­˜åœ¨"
    fi
}

dag_check "datamesh_mvp_pipeline"
dag_check "sample_data_mesh_pipeline"

# æ£€æŸ¥æœ€è¿‘è¿è¡Œ
echo ""
echo "  æœ€è¿‘ DAG è¿è¡Œ:"
recent_run=$(
  docker exec datamesh-airflow-scheduler airflow dags list-runs -d datamesh_mvp_pipeline -o plain 2>/dev/null \
    | sed '1d' \
    | head -1 \
  || true
)
if [ -n "$recent_run" ] && [[ ! "$recent_run" =~ "No data found" ]]; then
    echo -e "    ${GREEN}â†’${NC} $recent_run"
else
    echo -e "    ${YELLOW}â†’${NC} æš‚æ— è¿è¡Œè®°å½• (å¯æ‰‹åŠ¨è§¦å‘)"
fi

# ============================================
# 6. å¯è§‚æµ‹æ€§é“¾è·¯ (Prometheus æŒ‡æ ‡)
# ============================================
section "6. å¯è§‚æµ‹æ€§é“¾è·¯"

prom_query() {
    curl -s "http://localhost:9090/api/v1/query?query=$1" 2>/dev/null
}

prom_value() {
    # ä» Prometheus instant query JSON é‡Œå–ç¬¬ä¸€ä¸ª result çš„ value[1]
    # è¾“å‡ºä¸ºç©ºè¡¨ç¤ºæ²¡æœ‰æ•°æ®
    local query="$1"
    local json
    json=$(prom_query "$query" || true)
    python3 - <<'PY' "$json"
import sys, json
raw = sys.argv[1] if len(sys.argv) > 1 else ""
try:
    d = json.loads(raw) if raw else {}
    r = d.get("data", {}).get("result", [])
    print(r[0]["value"][1] if r else "")
except Exception:
    print("")
PY
}

# æ£€æŸ¥ probe_success (Blackbox exporter)
echo "  Blackbox æ¢æµ‹ (probe_success):"
probe_result=$(prom_query 'probe_success')
if echo "$probe_result" | grep -q '"result":\[' && ! echo "$probe_result" | grep -q '"result":\[\]'; then
    check_pass "Blackbox exporter æ­£åœ¨æ¢æµ‹æœåŠ¡"
else
    check_warn "Blackbox exporter æ— æ•°æ® (å¯èƒ½æœªå¯åŠ¨)"
fi

# æ£€æŸ¥è´¨é‡æŒ‡æ ‡ (Pushgateway)
echo ""
echo "  è´¨é‡æŒ‡æ ‡ (datamesh_quality_*):"
quality_result=$(prom_query 'datamesh_quality_pass_rate')
pass_rate=$(prom_value 'datamesh_quality_pass_rate')
if [ -n "$pass_rate" ]; then
    check_pass "datamesh_quality_pass_rate = $pass_rate%"
else
    check_warn "è´¨é‡æŒ‡æ ‡æœªæ¨é€ (è¿è¡Œ DAG åä¼šå‡ºç°)"
fi

# æ£€æŸ¥ up æŒ‡æ ‡
echo ""
echo "  æœåŠ¡å¥åº·æŒ‡æ ‡ (up):"
up_count_val=$(prom_value 'count(up)')
if [[ "$up_count_val" =~ ^[0-9]+(\\.[0-9]+)?$ ]] && [ "${up_count_val%%.*}" -gt 0 ]; then
    check_pass "Prometheus æ­£åœ¨ç›‘æ§ ${up_count_val} ä¸ª job"
else
    check_fail "Prometheus æ—  up æŒ‡æ ‡"
fi

# ============================================
# 7. ä¸šåŠ¡ KPI æ¦‚è§ˆ
# ============================================
section "7. ä¸šåŠ¡ KPI æ¦‚è§ˆ"

kpi_result=$(trino_row "SELECT total_customers, total_orders, total_revenue, pending_orders FROM mariadb.domain_analytics.dp_business_kpis" 2>/dev/null)
if [ -n "$kpi_result" ]; then
    # è§£æ KPI (æ ¼å¼: "value1","value2",...)
    IFS=$'\t' read -ra kpis <<< "$(echo "$kpi_result" | tr -d '\"')"
    echo -e "  ${GREEN}ğŸ“Š ä¸šåŠ¡æŒ‡æ ‡:${NC}"
    echo "    â€¢ å®¢æˆ·æ€»æ•°:   ${kpis[0]:-N/A}"
    echo "    â€¢ è®¢å•æ€»æ•°:   ${kpis[1]:-N/A}"
    echo "    â€¢ æ€»æ”¶å…¥:     \$${kpis[2]:-N/A}"
    echo "    â€¢ å¾…å¤„ç†è®¢å•: ${kpis[3]:-N/A}"
else
    check_warn "æ— æ³•è·å– KPI (æ•°æ®äº§å“å¯èƒ½æœªåˆå§‹åŒ–)"
fi

# ============================================
# 8. å…ƒæ•°æ®ç›®å½• (OpenMetadata)
# ============================================
section "8. å…ƒæ•°æ®ç›®å½• (OpenMetadata)"

token=""
if command -v python3 >/dev/null 2>&1; then
    # ä» openmetadata/mariadb-ingestion.yaml è¯»å– jwtTokenï¼ˆç”¨äºè°ƒç”¨å—ä¿æŠ¤ APIï¼‰
    token=$(python3 - <<'PY' "$PROJECT_DIR" 2>/dev/null || true
import sys
project_dir = sys.argv[1]
path = project_dir + "/openmetadata/mariadb-ingestion.yaml"
try:
    import yaml
    d = yaml.safe_load(open(path, "r", encoding="utf-8"))
    print(d["workflowConfig"]["openMetadataServerConfig"]["securityConfig"]["jwtToken"])
except Exception:
    print("")
PY
)
fi

auth_header=()
if [ -n "$token" ]; then
    auth_header=(-H "Authorization: Bearer $token")
fi

omd_tables=$(curl -s "${auth_header[@]}" "http://localhost:8585/api/v1/tables?limit=5" 2>/dev/null | grep -o '"name":"[^"]*"' | head -5 || echo "")
if [ -n "$omd_tables" ]; then
    check_pass "OpenMetadata æœ‰å·²æ³¨å†Œçš„è¡¨"
    echo "    ç¤ºä¾‹: $(echo "$omd_tables" | head -3 | sed 's/"name":"//g' | sed 's/"//g' | tr '\n' ', ' | sed 's/,$//')"
else
    if [ -z "$token" ]; then
        check_warn "OpenMetadata tables API éœ€è¦ tokenï¼ˆæ— æ³•è‡ªåŠ¨è¯»å– tokenï¼›è¯·ç¡®è®¤ openmetadata/mariadb-ingestion.yamlï¼‰"
    else
        check_warn "OpenMetadata æš‚æ— è¡¨ (è¿è¡Œ ./scripts/run-ingestion.sh)"
    fi
fi

# ============================================
# æ±‡æ€»æŠ¥å‘Š
# ============================================
echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                      éªŒè¯æ±‡æ€»                              â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo -e "  ${GREEN}âœ“ é€šè¿‡: $PASSED${NC}"
echo -e "  ${RED}âœ— å¤±è´¥: $FAILED${NC}"
echo -e "  ${YELLOW}âš  è­¦å‘Š: $WARNINGS${NC}"
echo ""

if [ $FAILED -eq 0 ]; then
    echo -e "  ${GREEN}ğŸ‰ Data Mesh MVP éªŒè¯é€šè¿‡ï¼${NC}"
    exit_code=0
else
    echo -e "  ${RED}âŒ æœ‰ $FAILED é¡¹æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹è¯¦æƒ…${NC}"
    exit_code=1
fi

echo ""
echo "â”â”â” å¿«é€Ÿè®¿é—® â”â”â”"
echo "  Trino UI:       http://localhost:8080"
echo "  Airflow UI:     http://localhost:8081  (admin/admin)"
echo "  OpenMetadata:   http://localhost:8585  (admin/admin)"
echo "  Superset:       http://localhost:8089  (admin/admin)"
echo "  Grafana:        http://localhost:3000  (admin/admin)"
echo "  Neo4j:          http://localhost:7474  (neo4j/datamesh123)"
echo "  Prometheus:     http://localhost:9090"
echo "  Jaeger:         http://localhost:16686"
echo ""
echo "â”â”â” ä¸‹ä¸€æ­¥ â”â”â”"
if [ $FAILED -gt 0 ] || [ $WARNINGS -gt 0 ]; then
    echo "  1. å¦‚æœæ•°æ®äº§å“ç¼ºå¤±:  ./scripts/init-data-products.sh"
    echo "  2. å¦‚æœå…ƒæ•°æ®ç¼ºå¤±:    ./scripts/run-ingestion.sh"
    echo "  3. è§¦å‘è´¨é‡æ£€æŸ¥ DAG:  Airflow UI â†’ datamesh_mvp_pipeline â†’ Trigger"
fi
echo "  4. æŸ¥çœ‹è´¨é‡æ—¥å¿—:      ./scripts/view-quality-logs.sh"
echo ""

exit $exit_code
